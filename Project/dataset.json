{
    "Explain the difference between supervised and unsupervised machine learning?": {
        "Marks": 5,
        "Answers": [
            "Supervised learning involves training a machine learning model on labeled data, while unsupervised learning involves training a model on unlabeled data.",
			"Supervised learning is used when the desired output is known, while unsupervised learning is used when the desired output is unknown.",
			"Supervised learning involves predicting a target variable, while unsupervised learning involves discovering patterns and relationships in the data.",
			"In supervised learning, the model is trained using a set of input/output pairs, while in unsupervised learning, the model is trained on the input data alone.",
			"Supervised learning can be used for classification or regression problems, while unsupervised learning can be used for clustering or dimensionality reduction.",
			"Supervised learning requires labeled data to train the model, while unsupervised learning does not require labeled data."
        ]
    },
    "Explain the difference between KNN and K-Means clustering?": {
        "Marks": 5,
        "Answers": [
			"KNN is a supervised machine learning algorithm used for classification and regression, while K-means is an unsupervised algorithm used for clustering.",
			"KNN is based on finding the k nearest neighbors to a data point, while K-means iteratively assigns data points to k clusters based on their similarity.",
			"KNN requires labeled data to train the model, while K-means does not require labeled data.",
			"KNN can handle non-linear data, while K-means assumes that clusters are spherical and separated by linear boundaries.",
			"KNN is computationally expensive during testing as it needs to compare the test point to all training data points, while K-means is less computationally expensive.",
			"KNN is more suitable for small datasets, while K-means can handle large datasets."
        ]
    },
    "What is the difference between classification and regression?": {
        "Marks": 5,
        "Answers": [
			"Classification is a type of supervised learning that categorizes data into discrete classes, while regression is a type of supervised learning that predicts a continuous numerical output.",
			"In classification, the output is a label or category, while in regression, the output is a value or quantity.",
			"Classification is used for tasks such as image recognition, spam filtering, and sentiment analysis, while regression is used for tasks such as stock price prediction, housing price prediction.",
			"Classification algorithms include decision trees, logistic regression, and support vector machines, while regression algorithms include linear regression, polynomial regression, and decision trees.",
			"The evaluation metrics used for classification include accuracy, precision, recall, and F1-score, while the evaluation metrics used for regression include mean squared error, mean absolute error, and R-squared.",
			"Classification algorithms are more suited to discrete data, while regression algorithms are more suited to continuous data."
        ]
    },
    "How to ensure that your model is not overfitting?": {
        "Marks": 5,
        "Answers": [
			"Use more data for training to prevent overfitting.",
			"Simplify the model to reduce complexity and overfitting.",
			"Regularize the model with techniques like L1/L2 regularization.",
			"Employ early stopping to prevent the model from fitting to the training data too closely.",
			"Use cross-validation to evaluate the model's performance on multiple test sets.",
			"Monitor the model's training and testing accuracy to detect overfitting."
        ]
    },
    "What are the different sets in which we divide any dataset for Machine Learning?": {
        "Marks": 5,
        "Answers": [
			"Training set: The data used to train the model.",
			"Validation set: The data used to evaluate the performance of the model during training.",
			"Test set: The data used to evaluate the final performance of the trained model.",
			"Development set: A subset of the training set used to tune hyperparameters and model architecture.",
			"Cross-validation set: The data used for evaluating model performance by splitting the dataset into multiple subsets.",
			"Holdout set: A randomly selected subset of the data used for model evaluation after training."
        ]
    },
    "Explain Dimensionality Reduction in machine learning?": {
        "Marks": 5,
        "Answers": [
			"Dimensionality reduction is a technique used to reduce the number of input features while retaining the most important information.",
			"It helps to simplify the dataset and avoid overfitting, as well as reduce the computational complexity of the model.",
			"Principal Component Analysis (PCA) is a popular method for dimensionality reduction.",
			"Other methods include Linear Discriminant Analysis (LDA), t-SNE, and Autoencoders.",
			"Dimensionality reduction can be used for data visualization and clustering.",
			"It is particularly useful for high-dimensional datasets where it is difficult to visualize the data and extract meaningful insights."
        ]
    },
    "Explain Dimensionality Reduction in machine learning?": {
        "Marks": 5,
        "Answers": [
			"Dimensionality Reduction is a process of reducing the number of features in a dataset.",
			"It is used to simplify complex datasets, improve computation efficiency, and avoid overfitting.",
			"Techniques such as Principal Component Analysis (PCA) and t-SNE are commonly used for Dimensionality Reduction.",
			"PCA is a linear method that transforms the data to new coordinate system while preserving the variance.",
			"t-SNE is a non-linear method that reduces the dimensionality of the data while preserving the local structure of the data.",
			"Dimensionality Reduction can lead to loss of information, so it's important to balance the trade-off between dimensionality reduction and information loss."
        ]
    },
    "Explain Ensemble learning?": {
        "Marks": 5,
        "Answers": [
			"Ensemble learning is a machine learning technique that combines the predictions of multiple models to improve accuracy.",
			"The idea behind ensemble learning is to create a more robust and accurate model by combining the strengths of multiple models.",
			"Ensemble learning can be used with various machine learning algorithms, such as decision trees, neural networks, and support vector machines.",
			"Ensemble learning can be achieved through techniques such as bagging, boosting, and stacking.",
			"Bagging involves training multiple models on different subsets of the training data and combining their predictions.",
			"Boosting involves sequentially training models on the same data, but giving more weight to examples that were previously misclassified."
        ]
    }
}
	
